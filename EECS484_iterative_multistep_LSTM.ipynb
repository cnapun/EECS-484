{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import os\n",
    "import holidays\n",
    "import pickle\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel('./GEFCom2014-E.xlsx')\n",
    "df['dow'] = df.Date.apply(lambda x: x.dayofweek)\n",
    "df['month'] = df.Date.apply(lambda x: x.month)\n",
    "df = df[df.load.isnull().sum():]\n",
    "ush = holidays.US()\n",
    "df['is_holiday'] = 1 * df.Date.apply(lambda x: x in ush)\n",
    "df = df.reindex(columns=('month', 'dow', 'Hour', 'is_holiday', 'T', 'load', 'Date'))\n",
    "offset = df.load.mean()\n",
    "scale = df.load.std()\n",
    "df.load -= df.load.mean()\n",
    "df.load /= df.load.std()\n",
    "df['T'] -= df['T'].mean()\n",
    "df['T'] /= df['T'].std()\n",
    "del df['Date']\n",
    "\n",
    "\n",
    "df.month = np.cos(2*np.pi/12*df.month)\n",
    "df.Hour = np.cos(2*np.pi/24*df.Hour)\n",
    "df.dow = np.cos(2*np.pi/7*df.dow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = df[:7*len(df)//8]\n",
    "# val = df[3*len(df)//4:7*len(df)//8]\n",
    "test = df[7*len(df)//8:]\n",
    "\n",
    "# train = data[:int(0.7*len(data))]\n",
    "# val = data[int(0.7*len(data)):int(0.9*len(data))]\n",
    "# test = data[int(0.9*len(data)):]\n",
    "\n",
    "nt = np.array(train)\n",
    "# nv = np.array(val)\n",
    "ntt = np.array(test)\n",
    "x_train = nt[:,:-1]\n",
    "y_train = nt[:,-1]\n",
    "x_val = ntt[:,:-1]\n",
    "y_val = ntt[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def row2seq_rnn(data, ys, history=24, future = 0):\n",
    "    xl = []\n",
    "    xff = []\n",
    "    yl = []\n",
    "    yf = []\n",
    "    for i in np.arange(history+1, len(data)-max(future,1)):\n",
    "        tmp1 = data[i-history:i+1]\n",
    "        tmp2 = ys[i-history-1:i].reshape(-1,1)\n",
    "        xl.append(np.append(tmp1, tmp2, axis=1))\n",
    "        xff.append(data[i+1:i+future+1])\n",
    "        yl.append(ys[i])\n",
    "        yf.append(ys[i:i+future+1])\n",
    "    return np.array(xl), np.array(xff), np.array(yl), np.array(yf)\n",
    "def batch(*vars, size=512):\n",
    "    for i in range(0, min(len(v) for v in vars), size):\n",
    "        yield (v[i:i+size] for v in vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xt, xtf, yt, ytf = row2seq_rnn(x_train, y_train, history=24, future=24)\n",
    "# xv, xvf, yv, yvf = row2seq_rnn(x_val, y_val, history=48, future=24)\n",
    "xtt, xttf, ytt, yttf = row2seq_rnn(np.array(test)[:,:-1], np.array(test)[:,-1], history=24, future=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xt.shape, xtf.shape, yt.shape, ytf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bs = 1024*2\n",
    "n_hidden = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cond = lambda i, s, p: i < t_max\n",
    "def body(i, s, preds):\n",
    "    tmp = tf.concat((xf[:,i], preds[:,-1:]), axis=1)\n",
    "    tmp.set_shape((None,xt.shape[-1]))\n",
    "    out, state = lstm(tmp, s)\n",
    "    new_pred = tf.layers.dense(out, 1, name='predict', reuse=True)\n",
    "    return tf.add(i,1), state, tf.concat((preds, new_pred), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ew = lambda: tf.nn.rnn_cell.LSTMStateTuple(tf.TensorShape((None, n_hidden)), tf.TensorShape((None, n_hidden)))\n",
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    x = tf.placeholder(tf.float32, (None, None, xt.shape[2]), name='x')\n",
    "    xf = tf.placeholder(tf.float32, (None, None, xtf.shape[2]), name='x_future')\n",
    "    y = tf.placeholder(tf.float32, (None), name='y')\n",
    "    yf = tf.placeholder(tf.float32, (None, None), name='y_future')\n",
    "    regularization = tf.placeholder_with_default(0.0, (), name='reg')\n",
    "    batch_size = tf.shape(x)[0]\n",
    "    learning_rate = tf.placeholder_with_default(0.001, (), name='learning_rate')\n",
    "    t_max = tf.shape(xf)[1]\n",
    "    lstm = tf.nn.rnn_cell.MultiRNNCell([tf.nn.rnn_cell.BasicLSTMCell(n_hidden) for _ in range(2)])\n",
    "    \n",
    "    outputs, state = tf.nn.dynamic_rnn(lstm, x, dtype=tf.float32)\n",
    "    for ttt in state:\n",
    "        for tt in ttt:\n",
    "            tt.set_shape((None, n_hidden))\n",
    "    i0 = tf.constant(0)\n",
    "    out0 = tf.layers.dense(outputs[:,-1], 1, name='predict')\n",
    "    \n",
    "    _, _, predictions = tf.while_loop(cond, body, loop_vars=[i0, state, out0],\n",
    "                        shape_invariants=[i0.get_shape(), \n",
    "                                          (ew(), ew()), tf.TensorShape([None, None])])\n",
    "    \n",
    "    single_pred = tf.layers.dense(outputs[:,-1], 1, name='predict', reuse=True)\n",
    "\n",
    "#     reg_loss = tf.add_n([tf.nn.l2_loss(i) for i in tf.trainable_variables() if 'bias' not in i.name])\n",
    "    err_loss = tf.reduce_mean((y[:,None]-single_pred)**2)\n",
    "    loss = err_loss\n",
    "#     loss = tf.reshape(reg_loss * regularization / tf.cast(batch_size, tf.float32), []) + err_loss\n",
    "    \n",
    "    err_losses = tf.reduce_mean((predictions-yf)**2)\n",
    "#     many_loss = tf.reshape(reg_loss * 0.005 / tf.cast(batch_size, tf.float32), []) + err_losses\n",
    "    many_loss = err_losses\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate).minimize(loss)\n",
    "    bigger_train_op = tf.train.AdamOptimizer(learning_rate).minimize(many_loss)\n",
    "    saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    while True:\n",
    "        tf.get_default_session().close()\n",
    "except:\n",
    "    pass\n",
    "sess = tf.InteractiveSession(graph=g)\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_epoch(lr=0.001, batch_size=bs):\n",
    "    perm = np.random.permutation(len(xt))\n",
    "    errrrs = []\n",
    "    for xs, ys, xfs, yfs in batch(xt[perm], yt[perm], xtf[perm], ytf[perm], size=batch_size):\n",
    "        _, l = sess.run((bigger_train_op, many_loss), feed_dict={x:xs, y:ys, xf:xfs, yf:yfs, learning_rate:lr})\n",
    "        errrrs.append(l)\n",
    "    return errrrs\n",
    "\n",
    "def evaluate(batch_size=bs):\n",
    "    ls = []\n",
    "    n = 0\n",
    "    perm = np.random.permutation(len(xtt))\n",
    "    for xs, ys, xfs, yfs in batch(xtt[perm], ytt[perm], xttf[perm], yttf[perm], size=batch_size):\n",
    "        ls.append(sess.run(many_loss, feed_dict={x:xs, y:ys, xf:xfs, yf:yfs,})*len(xs))\n",
    "        n += len(xs)\n",
    "    return np.sum(ls)/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_errs = []\n",
    "test_errs = []\n",
    "for i in range(len(test_errs), 300):\n",
    "    start = time.time()\n",
    "    train_err = train_epoch(batch_size=bs)\n",
    "    train_errs.extend(train_err)\n",
    "    test_errs.append(evaluate(bs*2))\n",
    "    end = time.time()\n",
    "\n",
    "    if i>1 and test_errs[-1]==min(test_errs):\n",
    "        saver.save(sess, './results/rnn_2L48h_24p_24f/model', global_step=len(test_errs))\n",
    "    print(f'Epoch {i} ({end-start:.2f}s): train_loss={train_errs[-1]:.4f}, test_loss={test_errs[-1]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(bs):\n",
    "    l = []\n",
    "    for xs, xfs, ys in batch(xtt, xttf,  ytt, size=bs):\n",
    "        l.append(sess.run(predictions, feed_dict={x:xs, xf:xfs, y:ys}))\n",
    "    return np.concatenate(l,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos = predict(bs*2)*scale + offset\n",
    "yov = yttf*scale + offset\n",
    "loss_by_horizon = ((yov-pos)**2).mean(0).astype(np.float32)\n",
    "loss_by_horizon"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
