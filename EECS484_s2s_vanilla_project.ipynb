{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from pyfiles import graph_creation\n",
    "import time\n",
    "import holidays\n",
    "import pickle\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_excel('../GEFCom2014 Data/GEFCom2014-E.xlsx')\n",
    "df['dow'] = df.Date.apply(lambda x: x.dayofweek)\n",
    "df['doy'] = df.Date.apply(lambda x: x.dayofyear)\n",
    "df['month'] = df.Date.apply(lambda x: x.month)\n",
    "df = df[df.load.isnull().sum():]\n",
    "ush = holidays.US()\n",
    "df['is_holiday'] = 1 * df.Date.apply(lambda x: x in ush)\n",
    "df = df.reindex(columns=('doy', 'month', 'dow', 'Hour', 'is_holiday', 'T', 'load', 'Date'))\n",
    "offset = df.load.mean()\n",
    "scale = df.load.std()\n",
    "df.load -= df.load.mean()\n",
    "df.load /= df.load.std()\n",
    "df['T'] -= df['T'].mean()\n",
    "df['T'] /= df['T'].std()\n",
    "del df['Date'], df['doy']\n",
    "\n",
    "\n",
    "df.month = np.cos(2*np.pi/12*df.month)\n",
    "df.Hour = np.cos(2*np.pi/24*df.Hour)\n",
    "df.dow = np.cos(2*np.pi/7*df.dow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = df[:7*len(df)//8]\n",
    "# val = df[3*len(df)//4:7*len(df)//8]\n",
    "test = df[7*len(df)//8:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "nt = np.array(train)\n",
    "# nv = np.array(val)\n",
    "ntt = np.array(test)\n",
    "x_train = nt[:,:-1]\n",
    "y_train = nt[:,-1]\n",
    "x_val = ntt[:,:-1]\n",
    "y_val = ntt[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def row2seq_rnn(data, ys, past=24, future=24):\n",
    "    xl = []\n",
    "    xfl = []\n",
    "    yl = []\n",
    "    for i in range(past, len(data)-future):\n",
    "        tmp1 = data[i-past:i]\n",
    "        tmp2 = ys[i-past:i, None]\n",
    "        xfl.append(data[i:i+future])\n",
    "        xl.append(np.append(tmp1, tmp2, axis=1))\n",
    "        yl.append(ys[i:i+future])\n",
    "    return np.array(xl), np.array(xfl), np.array(yl)\n",
    "def batch(*vars, size=512):\n",
    "    for i in range(0, min(len(v) for v in vars), size):\n",
    "        yield (v[i:i+size] for v in vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xt, xtf, yt = row2seq_rnn(x_train, y_train)\n",
    "xv, xvf, yv = row2seq_rnn(x_val, y_val)\n",
    "xtt, xttf, ytt = row2seq_rnn(ntt[:,:-1], ntt[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "hidden_dim = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = tf.Graph()\n",
    "with g.as_default():\n",
    "    x = tf.placeholder(tf.float32, (None, None, xt.shape[2]), name='x_past')\n",
    "    y = tf.placeholder(tf.float32, (None, None), name='y')\n",
    "    xf = tf.placeholder(tf.float32, (None, None, xtf.shape[2]), name='x_future')\n",
    "    keep_prob = tf.placeholder_with_default(1.0, (), name='keep_prob')\n",
    "    is_training = tf.placeholder_with_default(False, (), name='is_training')\n",
    "    regularization = tf.placeholder_with_default(0.005, (), name='regularization')\n",
    "    \n",
    "    out_weight = tf.Variable(tf.random_normal((hidden_dim,))/hidden_dim, dtype=tf.float32, name='out_weight')\n",
    "    out_bias = tf.Variable(tf.zeros(1), dtype=tf.float32, name='out_bias')\n",
    "    \n",
    "    # Basic seq2seq LSTM\n",
    "    outputs, _  = graph_creation.s2s_lstm_fixed(x, xf, hidden_dim, 2, use_bn=True, is_training=is_training, keep_prob=keep_prob, project=True)\n",
    "    \n",
    "    preds = tf.add(tf.einsum('ijk,k->ij', outputs, out_weight), out_bias, name='predictions')\n",
    "    loss = tf.reduce_mean((y-preds)**2)\n",
    "    reg_loss = tf.nn.l2_loss(out_weight) * regularization / tf.cast(tf.shape(x)[0], tf.float32)\n",
    "    step = tf.train.AdamOptimizer().minimize(loss+reg_loss)\n",
    "    saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    while True:\n",
    "        tf.get_default_session().close()\n",
    "except:\n",
    "    pass\n",
    "sess = tf.InteractiveSession(graph=g)\n",
    "saver = tf.train.Saver()\n",
    "sess.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_epoch(bs, keep_p=1.0):\n",
    "    perm = np.random.permutation(len(xt))\n",
    "    errors = []\n",
    "    for xs, xfs, ys in batch(xt[perm], xtf[perm], yt[perm], size=bs):\n",
    "        _, l = sess.run((step, loss), feed_dict={x:xs, xf:xfs, y:ys, keep_prob:keep_p, is_training:True})\n",
    "        errors.append(l)\n",
    "    return errors\n",
    "def evaluate(bs):\n",
    "    l = []\n",
    "    s = 0\n",
    "    for xs, xfs, ys in batch(xtt, xttf, ytt, size=bs):\n",
    "        l.append(sess.run(loss, feed_dict={x:xs, xf:xfs, y:ys})*len(ys))\n",
    "        s += len(ys)\n",
    "    return sum(l)/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bs = 1024*2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_errs = []\n",
    "test_errs = []\n",
    "for i in range(len(test_errs), 300):\n",
    "    start = time.time()\n",
    "    train_err = train_epoch(bs, 0.7)\n",
    "    train_errs.extend(train_err)\n",
    "    test_errs.append(evaluate(bs*2))\n",
    "    end = time.time()\n",
    "    if i>1 and test_errs[-1]==min(test_errs):\n",
    "        saver.save(sess, './eecs484results/2L48h_bn_0.3d_24p_24f_project/model', global_step=len(test_errs))\n",
    "    print(f'Epoch {i} ({end-start:.2f}s): train_loss={train_errs[-1]:.4f}, test_loss={test_errs[-1]:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(bs):\n",
    "    l = []\n",
    "    for xs, xfs, ys in batch(xtt, xttf,  ytt, size=bs):\n",
    "        l.append(sess.run(preds, feed_dict={x:xs, xf:xfs, y:ys}))\n",
    "    return np.concatenate(l,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos = predict(bs*2)*scale + offset\n",
    "yov = ytt*scale + offset\n",
    "loss_by_horizon = ((yov-pos)**2).mean(0).astype(np.float32)\n",
    "loss_by_horizon"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
